# This is an example of a workstation configuration file.

# The path to the directory where the data is stored
# (can also specify the path to a single fasta file)
fasta_path: examples/data

# The path to the directory where the output files will be stored.
# Will write a new subdirectory for each sequence containing the
# folded structure PDB file and a JSON file with the plddt score.
output_dir: examples/output

# The number of sequences to fold per worker function call.
chunk_size: 1


# The folding parameters to use (these parameters are for chai1)
folding_config:
    # The sequence type (e.g., protein, dna, rna, ligand).
    sequence_type: protein
    # Whether to use ESM embeddings.
    use_esm_embeddings: True
    # Number of trunk recycles.
    num_trunk_recycles: 3
    # Number of diffn timesteps.
    num_diffn_timesteps: 200
    # Random seed.
    seed: 42
    # Device to use (cpu or cuda).
    device: cuda
    # Path to the download directory.
    download_dir: examples/chai1
    # Temporary directory to store intermediate files.
    tmp_dir: /dev/shm

# The folding parameters (for ESMFold)
# folding_config_esmfold:
#     # Path to the torch hub directory.
#     torch_hub_dir: examples/torchhub

# The compute configuration to use.
compute_config:
    # Specify we want the workstation parsl configuration
    name: workstation
    # Identify which GPUs to assign tasks to. It's generally recommended to first check
    # nvidia-smi to see which GPUs are available. The numbers below are analogous to
    # setting CUDA_VISIBLE_DEVICES=0
    available_accelerators: ["0"]
